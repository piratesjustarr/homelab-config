# Yggdrasil Production Configuration
# Used for production deployments with high availability

environment: prod

hosts:
  - name: surtr-reasoning
    url: http://surtr:8081/v1
    model: gpt-oss:20b
    capabilities: [reasoning, complex, planning]
    priority: 1
    timeout_seconds: 120

  - name: fenrir-chat
    url: http://fenrir:8081/v1
    model: qwen2.5:7b
    capabilities: [chat, text, text-processing, summarize]
    priority: 1
    timeout_seconds: 120

  - name: skadi-code
    url: http://skadi:8080/v1
    model: granite-code:8b
    capabilities: [code, code-generation, code-review, code-fix]
    priority: 1
    timeout_seconds: 120

cloud_providers:
  - name: anthropic
    model: claude-sonnet-4-20250514
    capabilities: [code, reasoning, text, general, fallback]
    priority: 99
    timeout_seconds: 60

routing:
  code-generation: [code]
  code-review: [code, reasoning]
  code-fix: [code]
  text-processing: [text, chat]
  summarize: [text, chat]
  reasoning: [reasoning, complex]
  general: [general, chat]
  default: [general]

# Higher concurrency for production (monitor GPU util)
concurrency:
  surtr-reasoning: 2
  fenrir-chat: 3
  skadi-code: 2

# More aggressive retries for production reliability
retry:
  max_attempts: 3
  initial_delay_ms: 100
  max_delay_ms: 5000
  exponential_base: 2.0
  jitter: true

observability:
  enabled: true
  log_dir: /var/log/yggdrasil
  enable_metrics: true
  enable_error_tracking: true
  metrics_port: 8888

# Enable BeeAI in production (requires Python 3.12+)
beeai:
  enabled: true
  python_version: "3.12"
  fallback_to_simple_llm: true

beads_dir: /opt/yggdrasil/beads

log_level: INFO
